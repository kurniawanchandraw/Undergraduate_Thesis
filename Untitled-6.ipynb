{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0817bb66",
   "metadata": {},
   "source": [
    "# GTVC & GTWR Model Analysis with GNN Backbones, Weighting Schemes, and Loss Functions\n",
    "\n",
    "This notebook provides a structured analysis of GTVC and GTWR models using various GNN backbones, weighting schemes, and loss functions. The workflow includes data loading, model configuration, training, evaluation, and performance analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "699deadf",
   "metadata": {},
   "source": [
    "## 1. Import Required Libraries\n",
    "\n",
    "Import essential libraries for graph neural networks, data processing, and analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cddc00f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PyTorch & PyTorch Geometric\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch_geometric.data import Data, DataLoader\n",
    "from torch_geometric.nn import GCNConv, GATConv, SAGEConv\n",
    "\n",
    "# Other libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# For metrics and loss functions\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, log_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4af5911b",
   "metadata": {},
   "source": [
    "## 2. Load and Preprocess Graph Data\n",
    "\n",
    "Load the graph dataset, preprocess node and edge features, and prepare data loaders for training and evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "262f3234",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Load synthetic or custom graph data\n",
    "# Replace with actual data loading as needed\n",
    "\n",
    "def load_graph_data(path):\n",
    "    # Placeholder for loading graph data\n",
    "    # Should return PyTorch Geometric Data object\n",
    "    # Example: nodes, edges, features, labels\n",
    "    pass\n",
    "\n",
    "# Preprocessing function\n",
    "def preprocess_data(data):\n",
    "    # Normalize features, encode labels, etc.\n",
    "    return data\n",
    "\n",
    "# Load and preprocess\n",
    "graph_data = load_graph_data('your_graph_data_path')\n",
    "graph_data = preprocess_data(graph_data)\n",
    "\n",
    "# Split into train/test\n",
    "train_loader = DataLoader([graph_data], batch_size=1, shuffle=True)\n",
    "test_loader = DataLoader([graph_data], batch_size=1, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ed24506",
   "metadata": {},
   "source": [
    "## 3. Configure GTVC and GTWR Models\n",
    "\n",
    "Set up the GTVC and GTWR model architectures, including input/output dimensions and relevant hyperparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c18a9a70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example GTVC/GTWR base class\n",
    "class GTVC_GTWR_Base(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, backbone, weighting_scheme):\n",
    "        super().__init__()\n",
    "        self.backbone = backbone\n",
    "        self.weighting_scheme = weighting_scheme\n",
    "        self.fc = nn.Linear(in_channels, out_channels)\n",
    "    \n",
    "    def forward(self, data):\n",
    "        x, edge_index = data.x, data.edge_index\n",
    "        x = self.backbone(x, edge_index)\n",
    "        weights = self.weighting_scheme(x)\n",
    "        out = self.fc(weights)\n",
    "        return out\n",
    "\n",
    "# Hyperparameters\n",
    "in_channels = 16  # Example\n",
    "out_channels = 1  # Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "701c994c",
   "metadata": {},
   "source": [
    "## 4. Select GNN Backbone (GCN, GAT, GraphSAGE)\n",
    "\n",
    "Implement and select the desired GNN backbone for the models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee617e8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Backbone selection\n",
    "def get_gnn_backbone(name, in_channels, out_channels):\n",
    "    if name == 'GCN':\n",
    "        return GCNConv(in_channels, out_channels)\n",
    "    elif name == 'GAT':\n",
    "        return GATConv(in_channels, out_channels)\n",
    "    elif name == 'GraphSAGE':\n",
    "        return SAGEConv(in_channels, out_channels)\n",
    "    else:\n",
    "        raise ValueError(\"Unknown backbone\")\n",
    "\n",
    "# Example usage\n",
    "backbone_name = 'GCN'  # Change as needed\n",
    "gnn_backbone = get_gnn_backbone(backbone_name, in_channels, out_channels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e6a368a",
   "metadata": {},
   "source": [
    "## 5. Apply Weighting Schemes (Dot Product, Cosine Similarity, Kernel, MLP, Learned Attention)\n",
    "\n",
    "Integrate different weighting schemes into the models, allowing selection between dot product similarity, cosine similarity, kernel methods, MLP, or learned attention mechanisms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08c11211",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Weighting schemes\n",
    "class DotProductSimilarity(nn.Module):\n",
    "    def forward(self, x):\n",
    "        return torch.matmul(x, x.t())\n",
    "\n",
    "class CosineSimilarity(nn.Module):\n",
    "    def forward(self, x):\n",
    "        x_norm = x / x.norm(dim=1, keepdim=True)\n",
    "        return torch.mm(x_norm, x_norm.t())\n",
    "\n",
    "class KernelWeighting(nn.Module):\n",
    "    def forward(self, x):\n",
    "        gamma = 0.5\n",
    "        dist = torch.cdist(x, x)\n",
    "        return torch.exp(-gamma * dist)\n",
    "\n",
    "class MLPWeighting(nn.Module):\n",
    "    def __init__(self, in_channels):\n",
    "        super().__init__()\n",
    "        self.mlp = nn.Sequential(\n",
    "            nn.Linear(in_channels, 32),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(32, 1)\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        return self.mlp(x)\n",
    "\n",
    "class LearnedAttention(nn.Module):\n",
    "    def __init__(self, in_channels):\n",
    "        super().__init__()\n",
    "        self.attn = nn.Parameter(torch.randn(in_channels, 1))\n",
    "    def forward(self, x):\n",
    "        return torch.matmul(x, self.attn)\n",
    "\n",
    "# Example usage\n",
    "weighting_name = 'DotProduct'  # Change as needed\n",
    "if weighting_name == 'DotProduct':\n",
    "    weighting_scheme = DotProductSimilarity()\n",
    "elif weighting_name == 'Cosine':\n",
    "    weighting_scheme = CosineSimilarity()\n",
    "elif weighting_name == 'Kernel':\n",
    "    weighting_scheme = KernelWeighting()\n",
    "elif weighting_name == 'MLP':\n",
    "    weighting_scheme = MLPWeighting(in_channels)\n",
    "elif weighting_name == 'Attention':\n",
    "    weighting_scheme = LearnedAttention(in_channels)\n",
    "else:\n",
    "    raise ValueError(\"Unknown weighting scheme\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e788cf4",
   "metadata": {},
   "source": [
    "## 6. Configure Loss Functions (MSE, Huber, Focal, AICc, NLL)\n",
    "\n",
    "Set up and allow selection of various loss functions: Mean Squared Error (MSE), Huber, Focal, AICc, and Negative Log Likelihood (NLL)."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
